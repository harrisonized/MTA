{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D # VERY important to have capitalization\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option(\"max_rows\", 30)\n",
    "pd.set_option(\"max_columns\", None)\n",
    "pd.set_option(\"precision\", 3)\n",
    "\n",
    "import geocoder\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n",
    "with open(r'/home/harrisonized/Desktop/gmaps_apikey.txt') as f: # Grab API Key\n",
    "    api_key = f.readline()\n",
    "    f.close\n",
    "    \n",
    "gmaps.configure(api_key=api_key) # Fill in API Key\n",
    "\n",
    "# Working with hyperlinks\n",
    "import bs4\n",
    "import urllib3\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that formats the turnstile_data\n",
    "# Run after the turnstile file import\n",
    "\n",
    "def format_turnstile_df(turnstile_csv_df):\n",
    "\n",
    "    \"\"\"\n",
    "    turnstile_csv_df is the dataframe of the imported turnstile.csv file\n",
    "    Warning: Run once per file ONLY. The function will throw an error if run twice on the same file.\n",
    "    \"\"\"\n",
    "\n",
    "    global turnstile_df\n",
    "    turnstile_df = turnstile_csv_df\n",
    "    \n",
    "    # Reformatting steps (Warning: May take a few seconds.)\n",
    "    turnstile_df.columns = turnstile_df.columns.str.replace(' ','') # Remove spaces in column names\n",
    "    turnstile_df.columns = turnstile_df.columns.str.replace('/','') # Remove \"/\" in column names\n",
    "    turnstile_df['DATETIMERAW'] = \"\" # Create new column called 'DATETIMERAW'\n",
    "    turnstile_df['DATETIMERAW'] = turnstile_df.DATE + turnstile_df.TIME # Populate 'DATETIMERAW' with date and time concatenated string\n",
    "    turnstile_df.DATETIMERAW = turnstile_df.DATETIMERAW.apply(lambda x : dt.datetime.strptime(x, \"%m/%d/%Y%H:%M:%S\")) # Convert DATETIMERAW into datetime object\n",
    "    turnstile_df.TIME = turnstile_df.TIME.apply(lambda x : dt.datetime.strptime(x, \"%H:%M:%S\")) # Convert TIME into datetime object\n",
    "    turnstile_df = turnstile_df.drop(columns = ['DATE']) # Drop DATE column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function grabs data at two individual time stamps and outputs the difference in the count between those timestamps\n",
    "# This function references turnstile_df, which is the output of format_turnstile_df().\n",
    "# Note that this function is not explicitly run, but instead is run within the \n",
    "\n",
    "def valuecount(timestamp1, timestamp2):\n",
    "    \"\"\"\n",
    "    Timestamp inputs should be datetime objects. See example later. Also, timestamp2 should be greater than timestamp1.\n",
    "    \"\"\"\n",
    "    global value_count_df\n",
    "    \n",
    "    # Grabbing the data\n",
    "    turnstile_df1 = turnstile_df.loc[turnstile_df['DATETIMERAW'].isin([timestamp1])].reset_index(drop=True) # Grab dataset for timestamp1\n",
    "    turnstile_df2 = turnstile_df.loc[turnstile_df['DATETIMERAW'].isin([timestamp2])].reset_index(drop=True) # Grab dataset for timestamp2\n",
    "    \n",
    "    # Merge two datasets, drop any rows that don't form a complete dataset\n",
    "    turnstile_df_merge12 = turnstile_df1.merge(turnstile_df2.drop_duplicates(), on=[\"CA\", \"UNIT\", \"SCP\", \"STATION\", \"LINENAME\", \"DIVISION\", \"DESC\"], how='outer').dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Create a new dataframe with essential data\n",
    "    turnstile_df_valuecounts = turnstile_df_merge12[[\"STATION\"]] # Grabbing \"STATION\" name data\n",
    "    turnstile_df_valuecounts[\"ENTRIES DIFFERENCE\"] = (turnstile_df_merge12['ENTRIES_x'] - turnstile_df_merge12['ENTRIES_y']).abs() # Grabbing \"ENTRIES\" difference counts\n",
    "    turnstile_df_valuecounts[\"EXITS DIFFERENCE\"] = (turnstile_df_merge12['EXITS_x'] - turnstile_df_merge12['EXITS_y']).abs() # Grabbing \"EXITS\" difference counts\n",
    "    \n",
    "    # Computes the \"ENTRIES\" + \"EXITS\" for each counter\n",
    "    turnstile_df_valuecounts[\"TOTAL\"] = turnstile_df_valuecounts[\"ENTRIES DIFFERENCE\"] + turnstile_df_valuecounts[\"EXITS DIFFERENCE\"]  \n",
    "    \n",
    "    # Grab names of \"STATION\" and number of times they appear in turnstile_df_valuecounts\n",
    "    station_count = Counter(turnstile_df_valuecounts['STATION'])\n",
    "    station_dict = {i:station_count[i] for i in station_count}\n",
    "    \n",
    "    # For each \"STATION\" name, sum up all the counts from all units\n",
    "    value_count_dict = dict(zip(list(station_dict.keys()), [[turnstile_df_valuecounts.loc[turnstile_df_valuecounts['STATION'] == i, 'TOTAL'].sum()] for i in list(station_dict.keys())]))\n",
    "    \n",
    "    # Grab list of most popular stations and puts it into a sorted dataframe column\n",
    "    value_count_df = pd.DataFrame.from_dict(value_count_dict).transpose() # Grabbing values\n",
    "    value_count_df.columns = [\"ValueCount\"] # Renaming column to ValueCount\n",
    "    value_count_df = value_count_df.sort_values(by=[\"ValueCount\"], ascending=False) # Sorting by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the boundaries of the data pulled\n",
    "# This function references turnstile_df, which is the output of format_turnstile_df().\n",
    "\n",
    "def generate_timestamp_list():\n",
    "    \n",
    "    global timestamp_list\n",
    "    datetimeraw_count = Counter(turnstile_df['DATETIMERAW'])\n",
    "    \n",
    "    i = 0\n",
    "    timestamp_list = []\n",
    "    while min(datetimeraw_count) + dt.timedelta(hours=4*i) < max(datetimeraw_count):\n",
    "        timestamp_list.append(min(datetimeraw_count) + dt.timedelta(hours=4*i))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs for the whole week and enters it into a dataframe\n",
    "# This function references the timestamp_list AND calls upon the valuecount function.\n",
    "\n",
    "def grabweek():\n",
    "    global value_count_df_1to2\n",
    "\n",
    "    valuecount(timestamp_list[0], timestamp_list[1])\n",
    "    value_count_df_1to2 = value_count_df[[\"ValueCount\"]]\n",
    "    value_count_df_1to2.columns = [\"{}\".format(timestamp_list[0])]\n",
    "\n",
    "    for j in range(1, len(timestamp_list)-1):\n",
    "        valuecount(timestamp_list[j], timestamp_list[j+1])\n",
    "        value_count_df_1to2 = value_count_df_1to2.join(value_count_df[[\"ValueCount\"]])\n",
    "        value_count_df_1to2 = value_count_df_1to2.rename(columns={'ValueCount':\"{}\".format(str(timestamp_list[j]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import latlong_clean.csv, which was exported from a different notebook file.\n",
    "# This is used at the end after running the pipeline\n",
    "\n",
    "latlong_df = pd.read_csv(r\"latlong_clean.csv\")\n",
    "latlong_df = latlong_df.drop(columns={\"Unnamed: 0\", \"Numbering\"}) # Dropping the \"Unnamed: 0\" and \"Numbering\" column\n",
    "latlong_df.head() # Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing turnstile filenames for the last year from the MTA website\n",
    "\n",
    "URL = \"http://web.mta.info/developers/turnstile.html\"\n",
    "soup = bs4.BeautifulSoup(urlopen(URL))\n",
    "\n",
    "# Grabs all the links in the mta webpage\n",
    "all_link_list = []\n",
    "for link in soup.findAll('a'):\n",
    "    all_link_list.append(link.get('href'))\n",
    "\n",
    "# Dumps only the names for the last year into turnstile_link_list\n",
    "turnstile_link_list = [all_link_list[36:89][i].replace(\"data/nyct/turnstile/\", \"\") for i in range(len(link_list[36:89]))]\n",
    "turnstile_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstile_link_list[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This loops through the turnstile_link_list and outputs the turnstile_YYMMDD_proc.csv files.\n",
    "\n",
    "Notes:\n",
    "1. Use the \"20190405 Grabbing links from webpage\" file to download the turnstile_YYMMDD.txt files from the MTA website \"http://web.mta.info/developers/turnstile.html\"\n",
    "2. The turnstile_YYMMDD.txt files MUST be in the directory. If they are not, the loop will stop.\n",
    "3. Keep an eye on the loop, it stops if there are any issues with the processing of the file\n",
    "4. Files to skip: turnstile_190316.txt, turnstile_181110.txt\n",
    "5. Note: See below for files that weren't processed correctly due to daylight savings\n",
    "\n",
    "Warning: This may take a long time! On my computer, it outputs 2-3 files per minute and ran for 20 min+\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i in turnstile_link_list[25:len(turnstile_link_list)]: # Note, if loop stops, restart at an appropriate lowerbound for range\n",
    "\n",
    "    turnstile_df = pd.read_csv(i) # File imports\n",
    "    format_turnstile_df(turnstile_df) # Warning: Run once per file import ONLY\n",
    "\n",
    "    generate_timestamp_list() # Generating list of timestamps\n",
    "    grabweek() # Warning: May take a minute\n",
    "    value_count_df_1to2 = value_count_df_1to2.reset_index().rename(columns={\"index\":\"StationName\"})\n",
    "\n",
    "    # Merge coordinate data with value_count data\n",
    "    value_count_df_1to2_with_coord = latlong_df.merge(value_count_df_1to2, on=[\"StationName\"], how='left').reset_index(drop=True)\n",
    "    value_count_df_1to2_with_coord.head() # Preview the final data\n",
    "\n",
    "    value_count_df_1to2_with_coord.to_csv(\"{}_proc.csv\".format(i.replace(\".txt\",\"\")))\n",
    "    \n",
    "# Note: Graphing part was moved to next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following is for AFTER running the above loop and downloading as many files as possible\n",
    "\"\"\"\n",
    "turnstile_proc_list = [turnstile_link_list[i].replace(\".txt\", \"\")+\"_proc.csv\" for i in range(len(turnstile_link_list))]\n",
    "turnstile_proc_list.pop(2) # Removing 'turnstile_190316_proc.csv' from list\n",
    "turnstile_proc_list.pop(19) # Removing 'turnstile_181110_proc.csv' from list\n",
    "turnstile_proc_list # Show the list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through the files just to inspect them\n",
    "\n",
    "turnstile_proc_df = pd.read_csv(turnstile_proc_list[i])\n",
    "i += 1\n",
    "print(turnstile_proc_list[i])\n",
    "turnstile_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following items have a lot of missing values due to daylight savings.\n",
    "# See adjustment in generate_timestamp_list function below\n",
    "turnstile_link_list[3:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the boundaries of the data pulled\n",
    "# This function references turnstile_df, which is the output of format_turnstile_df().\n",
    "\n",
    "def generate_timestamp_list_dst():\n",
    "    \n",
    "    global timestamp_list\n",
    "    datetimeraw_count = Counter(turnstile_df['DATETIMERAW'])\n",
    "    \n",
    "    i = 0\n",
    "    timestamp_list = []\n",
    "    while min(datetimeraw_count) + dt.timedelta(hours=4*i) < max(datetimeraw_count):\n",
    "        timestamp_list.append(min(datetimeraw_count) + dt.timedelta(hours=4*i+3))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This loops through the turnstile_link_list and outputs the turnstile_YYMMDD_proc.csv files.\n",
    "This segment is just for the dates that are within (the opposite of) DST\n",
    "Warning! turnstile_190316.txt, turnstile_181110.txt still cannot be processed correctly and should be removed.\n",
    "\n",
    "Notes:\n",
    "1. Use the \"20190405 Grabbing links from webpage\" file to download the turnstile_YYMMDD.txt files from the MTA website \"http://web.mta.info/developers/turnstile.html\"\n",
    "2. The turnstile_YYMMDD.txt files MUST be in the directory. If they are not, the loop will stop.\n",
    "3. Keep an eye on the loop, it stops if there are any issues with the processing of the file\n",
    "\n",
    "Warning: This may take a long time! On my computer, it outputs 2-3 files per minute and ran for 10+ min.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i in turnstile_link_list[3:21]: # Note, if loop stops, restart at an appropriate lowerbound for range\n",
    "\n",
    "    turnstile_df = pd.read_csv(i) # File imports\n",
    "    format_turnstile_df(turnstile_df) # Warning: Run once per file import ONLY\n",
    "\n",
    "    generate_timestamp_list_dst() # Generating list of timestamps\n",
    "    grabweek() # Warning: May take a minute\n",
    "    value_count_df_1to2 = value_count_df_1to2.reset_index().rename(columns={\"index\":\"StationName\"})\n",
    "\n",
    "    # Merge coordinate data with value_count data\n",
    "    value_count_df_1to2_with_coord = latlong_df.merge(value_count_df_1to2, on=[\"StationName\"], how='left').reset_index(drop=True)\n",
    "    value_count_df_1to2_with_coord.head() # Preview the final data\n",
    "\n",
    "    value_count_df_1to2_with_coord.to_csv(\"{}_proc.csv\".format(i.replace(\".txt\",\"\")))\n",
    "    \n",
    "# Note: Graphing part was moved to next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
