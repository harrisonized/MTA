{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "import re\n",
    "import bs4\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import warnings # Turn off warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option(\"max_rows\", 30)\n",
    "pd.set_option(\"max_columns\", None)\n",
    "pd.set_option(\"precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_turnstile_df(turnstile_csv_df):\n",
    "\n",
    "    \"\"\"\n",
    "    turnstile_csv_df is the dataframe of the imported turnstile.csv file\n",
    "    Warning: Run once per file ONLY. The function will throw an error if run twice on the same file.\n",
    "    \"\"\"\n",
    "\n",
    "    global turnstile_df\n",
    "    turnstile_df = turnstile_csv_df\n",
    "    \n",
    "    # Reformatting steps (Warning: May take a few seconds.)\n",
    "    turnstile_df.columns = turnstile_df.columns.str.replace(' ','') # Remove spaces in column names\n",
    "    turnstile_df.columns = turnstile_df.columns.str.replace('/','') # Remove \"/\" in column names\n",
    "    turnstile_df['DATETIMERAW'] = \"\" # Create new column called 'DATETIMERAW'\n",
    "    turnstile_df['DATETIMERAW'] = turnstile_df.DATE + turnstile_df.TIME # Populate 'DATETIMERAW' with date and time concatenated string\n",
    "    turnstile_df.DATETIMERAW = turnstile_df.DATETIMERAW.apply(lambda x : dt.datetime.strptime(x, \"%m/%d/%Y%H:%M:%S\")) # Convert DATETIMERAW into datetime object\n",
    "    turnstile_df.TIME = turnstile_df.TIME.apply(lambda x : dt.datetime.strptime(x, \"%H:%M:%S\")) # Convert TIME into datetime object\n",
    "    turnstile_df = turnstile_df.drop(columns = ['DATE']) # Drop DATE column\n",
    "\n",
    "\n",
    "    \n",
    "def valuecount(timestamp1, timestamp2):\n",
    "    \"\"\"\n",
    "    This function references turnstile_df, which is the output of format_turnstile_df().\n",
    "    It grabs the data at two individual time stamps and outputs the difference in the count between those timestamps.\n",
    "    Both timestamp1 and timestamp2 should be datetime objects. Also, timestamp2 should be greater than timestamp1.\n",
    "    This function is not run as a standalone function. It is run within the grabweek() function.\n",
    "    \"\"\"\n",
    "    global value_count_df\n",
    "    \n",
    "    # Grabbing the data\n",
    "    turnstile_df1 = turnstile_df.loc[turnstile_df['DATETIMERAW'].isin([timestamp1])].reset_index(drop=True) # Grab dataset for timestamp1\n",
    "    turnstile_df2 = turnstile_df.loc[turnstile_df['DATETIMERAW'].isin([timestamp2])].reset_index(drop=True) # Grab dataset for timestamp2\n",
    "    \n",
    "    # Merge two datasets, drop any rows that don't form a complete dataset\n",
    "    turnstile_df_merge12 = turnstile_df1.merge(turnstile_df2.drop_duplicates(), on=[\"CA\", \"UNIT\", \"SCP\", \"STATION\", \"LINENAME\", \"DIVISION\", \"DESC\"], how='outer').dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Create a new dataframe with essential data\n",
    "    turnstile_df_valuecounts = turnstile_df_merge12[[\"STATION\"]] # Grabbing \"STATION\" name data\n",
    "    turnstile_df_valuecounts[\"ENTRIES DIFFERENCE\"] = (turnstile_df_merge12['ENTRIES_x'] - turnstile_df_merge12['ENTRIES_y']).abs() # Grabbing \"ENTRIES\" difference counts\n",
    "    turnstile_df_valuecounts[\"EXITS DIFFERENCE\"] = (turnstile_df_merge12['EXITS_x'] - turnstile_df_merge12['EXITS_y']).abs() # Grabbing \"EXITS\" difference counts\n",
    "    \n",
    "    # Computes the \"ENTRIES\" + \"EXITS\" for each counter\n",
    "    turnstile_df_valuecounts[\"TOTAL\"] = turnstile_df_valuecounts[\"ENTRIES DIFFERENCE\"] + turnstile_df_valuecounts[\"EXITS DIFFERENCE\"]  \n",
    "    \n",
    "    # Grab names of \"STATION\" and number of times they appear in turnstile_df_valuecounts\n",
    "    station_count = Counter(turnstile_df_valuecounts['STATION'])\n",
    "    station_dict = {i:station_count[i] for i in station_count}\n",
    "    \n",
    "    # For each \"STATION\" name, sum up all the counts from all units\n",
    "    value_count_dict = dict(zip(list(station_dict.keys()), [[turnstile_df_valuecounts.loc[turnstile_df_valuecounts['STATION'] == i, 'TOTAL'].sum()] for i in list(station_dict.keys())]))\n",
    "    \n",
    "    # Grab list of most popular stations and puts it into a sorted dataframe column\n",
    "    value_count_df = pd.DataFrame.from_dict(value_count_dict).transpose() # Grabbing values\n",
    "    value_count_df.columns = [\"ValueCount\"] # Renaming column to ValueCount\n",
    "    value_count_df = value_count_df.sort_values(by=[\"ValueCount\"], ascending=False) # Sorting by count\n",
    "\n",
    "    \n",
    "    \n",
    "def generate_timestamp_list():\n",
    "    \"\"\"\n",
    "    This function defines the boundaries of the data pulled. It references turnstile_df, which is the output of format_turnstile_df().\n",
    "    \"\"\" \n",
    "    global timestamp_list\n",
    "    datetimeraw_count = Counter(turnstile_df['DATETIMERAW'])\n",
    "    \n",
    "    i = 0\n",
    "    timestamp_list = []\n",
    "    while min(datetimeraw_count) + dt.timedelta(hours=4*i) < max(datetimeraw_count):\n",
    "        timestamp_list.append(min(datetimeraw_count) + dt.timedelta(hours=4*i))\n",
    "        i += 1\n",
    "\n",
    "        \n",
    "        \n",
    "def generate_timestamp_list_dst():\n",
    "    \"\"\"\n",
    "    This function defines the boundaries of the data pulled. It references turnstile_df, which is the output of format_turnstile_df().\n",
    "    \"\"\" \n",
    "    global timestamp_list\n",
    "    datetimeraw_count = Counter(turnstile_df['DATETIMERAW'])\n",
    "    \n",
    "    i = 0\n",
    "    timestamp_list = []\n",
    "    while min(datetimeraw_count) + dt.timedelta(hours=4*i) < max(datetimeraw_count):\n",
    "        timestamp_list.append(min(datetimeraw_count) + dt.timedelta(hours=4*i+3))\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "def grabweek():\n",
    "    \"\"\"\n",
    "    This function grabs data for the whole week and enters it into a dataframe\n",
    "    This function references the timestamp_list and calls upon the valuecount() function.\n",
    "    \"\"\"\n",
    "    global value_count_df_1to2\n",
    "\n",
    "    valuecount(timestamp_list[0], timestamp_list[1])\n",
    "    value_count_df_1to2 = value_count_df[[\"ValueCount\"]]\n",
    "    value_count_df_1to2.columns = [\"{}\".format(timestamp_list[0])]\n",
    "\n",
    "    for j in range(1, len(timestamp_list)-1):\n",
    "        valuecount(timestamp_list[j], timestamp_list[j+1])\n",
    "        value_count_df_1to2 = value_count_df_1to2.join(value_count_df[[\"ValueCount\"]])\n",
    "        value_count_df_1to2 = value_count_df_1to2.rename(columns={'ValueCount':\"{}\".format(str(timestamp_list[j]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs all the links in the mta webpage and collects the names for the last year into turnstile_link_list\n",
    "URL = \"http://web.mta.info/developers/turnstile.html\"\n",
    "soup = bs4.BeautifulSoup(urlopen(URL))\n",
    "all_link_list = []\n",
    "for link in soup.findAll('a'):\n",
    "    all_link_list.append(link.get('href'))\n",
    "turnstile_link_list = [all_link_list[36:89][i].replace(\"data/nyct/turnstile/\", \"\") for i in range(len(all_link_list[36:89]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationName</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34 ST-HERALD SQ</td>\n",
       "      <td>40.749</td>\n",
       "      <td>-73.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIMES SQ-42 ST</td>\n",
       "      <td>40.755</td>\n",
       "      <td>-73.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>40.751</td>\n",
       "      <td>-73.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59 ST COLUMBUS</td>\n",
       "      <td>40.768</td>\n",
       "      <td>-73.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86 ST</td>\n",
       "      <td>40.780</td>\n",
       "      <td>-73.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       StationName  Latitude  Longitude\n",
       "0  34 ST-HERALD SQ    40.749    -73.989\n",
       "1   TIMES SQ-42 ST    40.755    -73.987\n",
       "2   34 ST-PENN STA    40.751    -73.990\n",
       "3   59 ST COLUMBUS    40.768    -73.982\n",
       "4            86 ST    40.780    -73.956"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import latlong_clean.csv, which was exported from a different notebook file.\n",
    "\n",
    "latlong_df = pd.read_csv(r\"Coordinate Data/latlong_clean.csv\")\n",
    "latlong_df = latlong_df.drop(columns={\"Unnamed: 0\", \"Numbering\"}) # Dropping the \"Unnamed: 0\" and \"Numbering\" column\n",
    "latlong_df.head() # Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following part loops through the turnstile_link_list and outputs the turnstile_YYMMDD_proc.csv files.\n",
    "\n",
    "Notes:\n",
    "1. Use the \"20190405 Grabbing links from webpage.ipynb\" file to download the turnstile_YYMMDD.txt files from the MTA website \"http://web.mta.info/developers/turnstile.html\"\n",
    "2. The turnstile_YYMMDD.txt files MUST be in the directory. If they are not, the loop will stop.\n",
    "3. Keep an eye on the loop, it stops if there are any issues with the processing of the file\n",
    "4. Files to skip: turnstile_190316.txt, turnstile_181110.txt\n",
    "5. Note: See below for files that weren't processed correctly due to daylight savings\n",
    "\n",
    "Warning: This may take a long time! On my computer, it outputs 2-3 files per minute and ran for 20 min+.\n",
    "\"\"\"\n",
    "\n",
    "for i in turnstile_link_list[25:len(turnstile_link_list)]: # Note, if loop stops, restart at an appropriate lowerbound for range\n",
    "\n",
    "    turnstile_df = pd.read_csv(r\"Turnstile Data/Downloads/{}\".format(i)) # File imports\n",
    "    format_turnstile_df(turnstile_df) # Warning: Run once per file import ONLY\n",
    "\n",
    "    generate_timestamp_list() # Generating list of timestamps\n",
    "    grabweek() # Warning: May take a minute\n",
    "    value_count_df_1to2 = value_count_df_1to2.reset_index().rename(columns={\"index\":\"StationName\"})\n",
    "\n",
    "    # Merge coordinate data with value_count data\n",
    "    value_count_df_1to2_with_coord = latlong_df.merge(value_count_df_1to2, on=[\"StationName\"], how='left').reset_index(drop=True)\n",
    "    value_count_df_1to2_with_coord.head() # Preview the final data\n",
    "\n",
    "    value_count_df_1to2_with_coord.to_csv(r\"Turnstile Data/Processed CSV/{}_proc.csv\".format(i.replace(\".txt\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turnstile_181201_proc.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following is for AFTER running the above loop and downloading as many files as possible\n",
    "\"\"\"\n",
    "turnstile_proc_list = [turnstile_link_list[i].replace(\".txt\", \"\")+\"_proc.csv\" for i in range(len(turnstile_link_list))]\n",
    "turnstile_proc_list.pop(2) # Removing 'turnstile_190316_proc.csv' from list\n",
    "turnstile_proc_list.pop(19) # Removing 'turnstile_181110_proc.csv' from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turnstile_190330.txt',\n",
       " 'turnstile_190323.txt',\n",
       " 'turnstile_190316.txt',\n",
       " 'turnstile_190309.txt',\n",
       " 'turnstile_190302.txt',\n",
       " 'turnstile_190223.txt',\n",
       " 'turnstile_190216.txt',\n",
       " 'turnstile_190209.txt',\n",
       " 'turnstile_190202.txt',\n",
       " 'turnstile_190126.txt',\n",
       " 'turnstile_190119.txt',\n",
       " 'turnstile_190112.txt',\n",
       " 'turnstile_190105.txt',\n",
       " 'turnstile_181229.txt',\n",
       " 'turnstile_181222.txt',\n",
       " 'turnstile_181215.txt',\n",
       " 'turnstile_181208.txt',\n",
       " 'turnstile_181201.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following items have a lot of missing values due to daylight savings.\n",
    "# See adjustment in generate_timestamp_list function below\n",
    "turnstile_link_list[3:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This loops through the turnstile_link_list and outputs the turnstile_YYMMDD_proc.csv files.\n",
    "This segment is just for the dates that are within (the opposite of) DST\n",
    "Warning! turnstile_190316.txt, turnstile_181110.txt still cannot be processed correctly and should be removed.\n",
    "\n",
    "Notes:\n",
    "1. Use the \"20190405 Grabbing links from webpage\" file to download the turnstile_YYMMDD.txt files from the MTA website \"http://web.mta.info/developers/turnstile.html\"\n",
    "2. The turnstile_YYMMDD.txt files MUST be in the directory. If they are not, the loop will stop.\n",
    "3. Keep an eye on the loop, it stops if there are any issues with the processing of the file\n",
    "\n",
    "Warning: This may take a long time! On my computer, it outputs 2-3 files per minute and ran for 10+ min.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i in turnstile_link_list[3:21]: # Note, if loop stops, restart at an appropriate lowerbound for range\n",
    "\n",
    "    turnstile_df = pd.read_csv(r\"Turnstile Data/Downloads/{}\".format(i)) # File imports\n",
    "    format_turnstile_df(turnstile_df) # Warning: Run once per file import ONLY\n",
    "\n",
    "    generate_timestamp_list_dst() # Generating list of timestamps\n",
    "    grabweek() # Warning: May take a minute\n",
    "    value_count_df_1to2 = value_count_df_1to2.reset_index().rename(columns={\"index\":\"StationName\"})\n",
    "\n",
    "    # Merge coordinate data with value_count data\n",
    "    value_count_df_1to2_with_coord = latlong_df.merge(value_count_df_1to2, on=[\"StationName\"], how='left').reset_index(drop=True)\n",
    "    value_count_df_1to2_with_coord.head() # Preview the final data\n",
    "\n",
    "    value_count_df_1to2_with_coord.to_csv(r\"Turnstile Data/Processed CSV/{}_proc.csv\".format(i.replace(\".txt\",\"\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
